logging:
  level: INFO
  path: ./outputs/logs

paths:
## INPUTS
  features: ./outputs/features
  tokenized: ./outputs/tokenized
  cohort: ./outputs/cohort_absolute  # path to cohort directory
  outcomes: ./outputs/outcomes
  outcome: TEST_OUTCOME.csv

  # tokenized_file: ...
  # tokenized_pids: ...
  
## OUTPUTS
  prepared_data: ./outputs/oot_all/processed_data/ # Save model/outputs to this folder
  #runs: ./outputs/pretraining # Use for generating a new model folder

data:
  type: "all"
  val_ratio: 0.2 # only used if predefined_splits is false
  truncation_len: 20
  min_len: 2
  predefined_splits: false # set to true if you want to use predefined splits for reproducibility. Expects a list (of length 1) of dicts with train, val created by select_cohort
  
outcome: # we will convert outcomes to binary based on whether at least one outcome is in the follow up window
  n_hours_censoring: 0 # censor time after index date (negative means before)
  n_hours_start_follow_up: 1 # start follow up (considering outcomes) time after index date (negative means before)
  n_hours_end_follow_up: 8500 # end follow up (considering outcomes) time after index date (negative means before)
